{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9ac42e4-d207-4c86-9103-5792770b2cef",
   "metadata": {},
   "source": [
    "# Multi agent systems with tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f080ef7-6424-4972-ad37-1a3de41acef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages,AnyMessage\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import Image, display\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import Runnable\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langchain_core.messages import ToolMessage\n",
    "from enum import Enum\n",
    "from langchain_core.pydantic_v1 import BaseModel,Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e8113f7-ec5d-406a-82bd-ab38781b4e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-4o\", temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48374aa5-ab92-4a93-9617-b30288c257dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATE\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list,add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68e92ec1-e1c5-40c4-a6d4-9554848a4f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class agents(str,Enum):\n",
    "    multi_agent = \"multi_agent\"\n",
    "    numeric_agent = \"numeric_agent\"\n",
    "    story_agent = \"story_agent\"\n",
    "    connecting_agent = \"connecting_agent\"\n",
    "    connecting_num_agent = \"connecting_num_agent\"\n",
    "    connecting_story_agent = \"connecting_story_agent\"\n",
    "    checking_tools = \"checking_tools\"\n",
    "    leave_skill = \"leave_skill\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cf73c48-78c9-472c-b4d0-bcbf6209abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRY NODE FOR CONNECTING_AGENT(entry_node is a tool message)\n",
    "\n",
    "def create_entry_node(assistant_name:str, new_dialogue_state: str) -> str:\n",
    "    def entry_node(state: State)->dict:\n",
    "        tool_call_id = state['messages'][-1].tool_calls[0][\"id\"]\n",
    "        return {\n",
    "            \"messages\":[ToolMessage(content = \n",
    "            f\"\"\"The assistant is now the {assistant_name}. Reflect on the above conversation\n",
    "            between the host assistant and the user.The user's intent is unsatisfied.\n",
    "            Use the provided tools to assist the user. Remember, you are {assistant_name},\n",
    "            If the user is trying to perform operations that are not supported by you\n",
    "            then call the CompleteOrEscalate. If the user changes their mind or needs\n",
    "            help for other tasks, call the CompleteOrEscalate function to let the primary\n",
    "            host assistant take control.Do not mention who you are - just act as the\n",
    "            proxy for the assistant.\"\"\",\n",
    "\n",
    "                        tool_call_id = tool_call_id,)],\n",
    "            \"dialog_state\" : pop_dialog_state\n",
    "            \n",
    "        }\n",
    "    return entry_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b994d9fc-e1d2-40d1-86f1-effa2c7811f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompleteOrEscalate(BaseModel):\n",
    "    \"\"\"A tool to mark the current task as completed and/or to escalate\n",
    "    control of the dialog to the main assistant, who can re-route the dialog\n",
    "    based on the user's needs.\"\"\"\n",
    "\n",
    "    cancel: bool = True\n",
    "    reason: str\n",
    "\n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"cancel\": True,\n",
    "                \"reason\": \"User changed their mind about the current task.\",\n",
    "            },\n",
    "            \"example 2\": {\n",
    "                \"cancel\": True,\n",
    "                \"reason\": \"I have fully completed the task.\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "# This node will be shared for exiting all specialized assistants\n",
    "def pop_dialog_state(state: State) -> dict:\n",
    "    \"\"\"Pop the dialog stack and return to the main assistant.\n",
    "\n",
    "    This lets the full graph explicitly track the dialog flow and delegate\n",
    "    control to specific sub-graphs.\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    if state[\"messages\"][-1].tool_calls:\n",
    "        messages.append(\n",
    "            ToolMessage(\n",
    "                content=\"\"\"Resuming dialog with the host assistant. Please\n",
    "reflect on the past conversation and assist the user as needed.\"\"\",\n",
    "                tool_call_id=state[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "            )\n",
    "        )\n",
    "    return {\n",
    "        \"dialog_state\": \"pop\",\n",
    "        \"messages\": messages,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f02198bf-6fab-4a86-b56c-6b057b9d798f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOOLS\n",
    "\n",
    "@tool\n",
    "def check() -> str:\n",
    "    \"\"\"\n",
    "    Call this tool before responding to the user to check if your response is valid.\n",
    "    \"\"\"\n",
    "    return \"Your response is valid\"\n",
    "\n",
    "class ToNumericAssistant(BaseModel):\n",
    "    \"\"\"\n",
    "    Transfers work to a specialized to handle numeric operations. This tool does not perform any operation that are not related to numbers\n",
    "    \"\"\"\n",
    "    request: str = Field(\n",
    "        description=\"\"\"\n",
    "        Any additional information or requests from the user\n",
    "        regarding the numeric operation.\"\"\"\n",
    "    )\n",
    "    reason: str = Field(\n",
    "        description=\"Reason why this tool is used for the operation\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ToStoryAssistant(BaseModel):\n",
    "    \"\"\"\n",
    "    Transfers work to a specialized to handle creation of stories. This tool does not perform any operation that are not related to story.\n",
    "    \"\"\"\n",
    "    request: str = Field(\n",
    "        description=\"\"\"\n",
    "        Any additional information or requests from the user\n",
    "        regarding the story creation.\"\"\"\n",
    "    )\n",
    "    reason: str = Field(\n",
    "        description=\"Reason why this tool is used for the operation\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b054c2a-4a41-4e85-aa2e-52a743ebdb44",
   "metadata": {},
   "source": [
    "## NUMERIC AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8be2aa6-3217-4c9d-826d-bbb83e963f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINING AGENT\n",
    "def numeric_agent(state:State):\n",
    "    response = numeric_chain(llm).invoke({\"messages\":state[\"messages\"]})\n",
    "    return {\"messages\":[response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3690b49c-d67c-4a27-88cd-046b9667d514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOOLS\n",
    "\n",
    "@tool\n",
    "def numeric_tool(query: str) -> str:\n",
    "    \"\"\"You are an AI assistant for solving numeric problems.\"\"\"\n",
    "    operators = \"\"\"\n",
    "    \n",
    "    Evaluates a numeric expression. Supports basic arithmetic and\n",
    "    some advanced operations like factorial, exponentiation, and modulo.\n",
    "    \n",
    "    Supported operations:\n",
    "    - Addition (+)\n",
    "    - Subtraction (-)\n",
    "    - Multiplication (*)\n",
    "    - Division (/)\n",
    "    - Floor division (//)\n",
    "    - Modulus (%)\n",
    "    - Exponentiation (** or ^)\n",
    "    - Factorial (!) \n",
    "    \n",
    "    Example usage:\n",
    "    - \"5 + 3 * 2\"\n",
    "    - \"10 / 2\"\n",
    "    - \"4!\"\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "tools = [numeric_tool]\n",
    "tool_node = ToolNode(tools)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa411ab0-4281-4e20-9f0d-30b0f924e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROMPTS\n",
    "\n",
    "numeric_agent_system_prompt = \"\"\"\n",
    "\n",
    "You are an AI assistant and your job is to solve numeric operations.\n",
    "Don't provide with any other activities.\n",
    "\n",
    "You are provided with numeric_tool to perform operations.\n",
    "Don't use anything outside this tool.\n",
    "Do not try to be conversational\n",
    "\n",
    "Always use CompleteOrEscalate tool after completing. If you are calling CompleteOrEscalate then explain the reason\n",
    "If the user needs help, and you did not find appropriate function after searching, then \n",
    "CompleteOrEscalate the dialog to the host assistant. Do not waste the users time. Do not make up invalid tools or functions.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "numeric_agent_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", numeric_agent_system_prompt),\n",
    "        (\"placeholder\", \"{messages}\"),])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91eef1f3-ace2-45b2-9455-3222831735e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHAINS\n",
    "def numeric_chain(llm):\n",
    "    return ( numeric_agent_prompt\n",
    "            | llm.bind_tools(                \n",
    "                [\n",
    "                    numeric_tool,CompleteOrEscalate\n",
    "                ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c07bbc18-6a27-4d81-8dd6-d05ef386ae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUTER\n",
    "def numeric_route(state: State):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    route = tools_condition(state)\n",
    "    if route == END:\n",
    "        return agents.leave_skill\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    print(tool_calls)\n",
    "    if tool_calls:\n",
    "        tool_name = tool_calls[0][\"name\"]\n",
    "        if tool_name == \"numeric_tool\":\n",
    "            print(10 * \"#\")\n",
    "            print(tool_name)\n",
    "            print(10 * \"#\")\n",
    "            return 'tools'\n",
    "        elif tool_name == CompleteOrEscalate.__name__:\n",
    "            return agents.leave_skill\n",
    "    else:\n",
    "        raise ValueError(\"invalid tool call\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe8c548d-545a-4234-a2ff-99ef7a2bf4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow (to go to one agent to another agent we need connectind_agent(tool message))\n",
    "def numeric_builder(graph_builder:StateGraph, llm:Runnable) -> StateGraph:\n",
    "    graph_builder.add_node(agents.connecting_num_agent,create_entry_node(\"Tool message before going to numeric_agent\",agents.numeric_agent))\n",
    "    graph_builder.add_node(agents.numeric_agent, numeric_agent)\n",
    "    graph_builder.add_edge(agents.connecting_num_agent,agents.numeric_agent)\n",
    "    graph_builder.add_conditional_edges(agents.numeric_agent,numeric_route)\n",
    "    graph_builder.add_node(\"tools\", tool_node)\n",
    "    graph_builder.add_edge(\"tools\", \"numeric_agent\")\n",
    "    return graph_builder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07591d73-325f-4111-8f92-cc5e78450dfe",
   "metadata": {},
   "source": [
    "## STORY AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51f407b9-22bb-43a6-9819-31cf1b9592e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINING AGENT\n",
    "def story_agent(state:State):\n",
    "    response = story_chain(llm).invoke({\"messages\":state[\"messages\"]})\n",
    "    return {\"messages\":[response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a972d31d-1c04-4a9e-952f-53d2edb800ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROMPTS\n",
    "\n",
    "story_agent_system_prompt = \"\"\"\n",
    "You are an assistant and your task is to generate a unique love story with whatever query users give.\n",
    "You should only accept the queries related to generation of stories, nothing else should be accepted.\n",
    "Don't perform any other activities.Only give stories. \n",
    "Generate a story of 5 lines.\n",
    "\"\"\"\n",
    "\n",
    "story_agent_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", story_agent_system_prompt),\n",
    "        (\"placeholder\", \"{messages}\"),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce76eca8-df9a-43e7-9a38-ec4607ead545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHAINS\n",
    "def story_chain(llm):\n",
    "    return ( story_agent_prompt|llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "522c1c64-4168-4923-9c88-7b8a69ee2e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow\n",
    "def story_builder(graph_builder:StateGraph, llm:Runnable) -> StateGraph:\n",
    "    graph_builder.add_node(agents.connecting_story_agent,create_entry_node(\"Tool message before going to story_agent\",agents.story_agent))\n",
    "    graph_builder.add_node(agents.story_agent, story_agent)\n",
    "    graph_builder.add_edge(agents.connecting_story_agent,agents.story_agent)\n",
    "    \n",
    "    return graph_builder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3031137e-3087-4e25-a399-85e5262ef5b9",
   "metadata": {},
   "source": [
    "## MAIN AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1617014c-b87e-49c7-992e-303973f95fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPTS\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "multi_system_prompt = \"\"\"\n",
    "\n",
    "You do not have any knowledge of Mathematics and stories. You should only use the information provided by the assistants\n",
    " Ask for user what things needs to be done.\n",
    " \n",
    "Do not perform activities that are not directly supported by the defined agents.\n",
    "Always call the checking tool to check if the generated answer is valid.\n",
    "\"\"\"\n",
    "multi_agent_prompt = ChatPromptTemplate.from_messages(\n",
    "[(\n",
    "            \"system\",\n",
    "            multi_system_prompt,\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba0b4885-8cac-4aba-aaf6-1074280a2cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHAINS\n",
    "\n",
    "def multi_agent_chain(llm):\n",
    "    return(\n",
    "        multi_agent_prompt | llm.bind_tools(\n",
    "            [\n",
    "                check,\n",
    "                ToNumericAssistant,\n",
    "                ToStoryAssistant,\n",
    "            ],\n",
    "            parallel_tool_calls = False\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7be88fa-df50-4324-ae1f-c14b7c1e1835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINING AGENTS\n",
    "\n",
    "def multi_agent(state: State):\n",
    "    response = multi_agent_chain(llm).invoke({\"messages\":state[\"messages\"]})\n",
    "    return {\"messages\":[response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6b1106e-fe98-4ac4-8f14-196023a42740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUTER\n",
    "\n",
    "def route_agent(state: State):\n",
    "    route = tools_condition(state)\n",
    "    if route == END:\n",
    "        return END\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    if tool_calls:\n",
    "        tool_name = tool_calls[0][\"name\"]\n",
    "        if tool_name == ToNumericAssistant.__name__:\n",
    "            return agents.connecting_num_agent\n",
    "        elif tool_name == ToStoryAssistant.__name__:\n",
    "            return agents.connecting_story_agent\n",
    "        elif tool_name == \"check\":\n",
    "            return agents.checking_tools\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6132d142-8f7d-41b6-92a1-3618f68e2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAPH\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(agents.multi_agent, multi_agent)\n",
    "graph_builder.add_edge(START, agents.multi_agent)\n",
    "graph_builder.add_conditional_edges(agents.multi_agent, route_agent)\n",
    "graph_builder.add_node(agents.leave_skill, pop_dialog_state)\n",
    "graph_builder.add_edge(agents.leave_skill, agents.multi_agent)\n",
    "graph_builder.add_node(agents.checking_tools, ToolNode(tools = [check]))\n",
    "graph_builder.add_edge(agents.checking_tools, agents.multi_agent)\n",
    "\n",
    "\n",
    "graph_builder = numeric_builder(graph_builder,llm)\n",
    "graph_builder = story_builder(graph_builder,llm)\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59e40b95-ba62-496e-b218-56e5a2ad496d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what is 4!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is 4!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  ToNumericAssistant (call_dWcFAR1JE8FLDcB4AQirB7nM)\n",
      " Call ID: call_dWcFAR1JE8FLDcB4AQirB7nM\n",
      "  Args:\n",
      "    request: Calculate 4! (4 factorial)\n",
      "    reason: Factorial calculation is a numeric operation.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "The assistant is now the Tool message before going to numeric_agent. Reflect on the above conversation\n",
      "            between the host assistant and the user.The user's intent is unsatisfied.\n",
      "            Use the provided tools to assist the user. Remember, you are Tool message before going to numeric_agent,\n",
      "            If the user is trying to perform operations that are not supported by you\n",
      "            then call the CompleteOrEscalate. If the user changes their mind or needs\n",
      "            help for other tasks, call the CompleteOrEscalate function to let the primary\n",
      "            host assistant take control.Do not mention who you are - just act as the\n",
      "            proxy for the assistant.\n",
      "[{'name': 'numeric_tool', 'args': {'query': 'Calculate 4!'}, 'id': 'call_5lBVDHLUpv94HX7DYSGRoVP8', 'type': 'tool_call'}]\n",
      "##########\n",
      "numeric_tool\n",
      "##########\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  numeric_tool (call_5lBVDHLUpv94HX7DYSGRoVP8)\n",
      " Call ID: call_5lBVDHLUpv94HX7DYSGRoVP8\n",
      "  Args:\n",
      "    query: Calculate 4!\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: numeric_tool\n",
      "\n",
      "null\n",
      "[{'name': 'CompleteOrEscalate', 'args': {'reason': 'The numeric operation 4! (4 factorial) has been calculated.'}, 'id': 'call_QtLTykIBN9KElEdWIcXKRuOQ', 'type': 'tool_call'}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  CompleteOrEscalate (call_QtLTykIBN9KElEdWIcXKRuOQ)\n",
      " Call ID: call_QtLTykIBN9KElEdWIcXKRuOQ\n",
      "  Args:\n",
      "    reason: The numeric operation 4! (4 factorial) has been calculated.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Resuming dialog with the host assistant. Please\n",
      "reflect on the past conversation and assist the user as needed.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The factorial of 4 (4!) is 24. If you have any other questions or need further assistance, feel free to ask!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  create a story\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "create a story\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  ToStoryAssistant (call_ZdsmAzEdgKzrQ9SxSpDpSZlQ)\n",
      " Call ID: call_ZdsmAzEdgKzrQ9SxSpDpSZlQ\n",
      "  Args:\n",
      "    request: Please create a story.\n",
      "    reason: The user requested a story to be created.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "The assistant is now the Tool message before going to story_agent. Reflect on the above conversation\n",
      "            between the host assistant and the user.The user's intent is unsatisfied.\n",
      "            Use the provided tools to assist the user. Remember, you are Tool message before going to story_agent,\n",
      "            If the user is trying to perform operations that are not supported by you\n",
      "            then call the CompleteOrEscalate. If the user changes their mind or needs\n",
      "            help for other tasks, call the CompleteOrEscalate function to let the primary\n",
      "            host assistant take control.Do not mention who you are - just act as the\n",
      "            proxy for the assistant.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "In a quaint village nestled between rolling hills, lived a young artist named Elara. Every morning, she painted the sunrise, capturing its beauty on her canvas. One day, a traveler named Finn, with a heart full of wanderlust, stumbled upon her work. Mesmerized by her art, he stayed to watch her paint, and their conversations blossomed into a deep connection. As the seasons changed, so did their love, growing stronger with each sunrise they shared together.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  create a sad ending with 15 lines of story\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "create a sad ending with 15 lines of story\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  ToStoryAssistant (call_iJF6Lt3NQUArUUJaAEwmMd1k)\n",
      " Call ID: call_iJF6Lt3NQUArUUJaAEwmMd1k\n",
      "  Args:\n",
      "    request: create a sad ending with 15 lines of story\n",
      "    reason: The user requested a story with a sad ending\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "The assistant is now the Tool message before going to story_agent. Reflect on the above conversation\n",
      "            between the host assistant and the user.The user's intent is unsatisfied.\n",
      "            Use the provided tools to assist the user. Remember, you are Tool message before going to story_agent,\n",
      "            If the user is trying to perform operations that are not supported by you\n",
      "            then call the CompleteOrEscalate. If the user changes their mind or needs\n",
      "            help for other tasks, call the CompleteOrEscalate function to let the primary\n",
      "            host assistant take control.Do not mention who you are - just act as the\n",
      "            proxy for the assistant.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I can only generate stories that are 5 lines long. Would you like a 5-line story with a sad ending instead?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  create a sad ending with 5 lines\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "create a sad ending with 5 lines\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  ToStoryAssistant (call_yQZ8ky3ng30R8fe4iBOnSZ0x)\n",
      " Call ID: call_yQZ8ky3ng30R8fe4iBOnSZ0x\n",
      "  Args:\n",
      "    request: create a sad ending with 5 lines\n",
      "    reason: The user requested a sad ending for a story.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "The assistant is now the Tool message before going to story_agent. Reflect on the above conversation\n",
      "            between the host assistant and the user.The user's intent is unsatisfied.\n",
      "            Use the provided tools to assist the user. Remember, you are Tool message before going to story_agent,\n",
      "            If the user is trying to perform operations that are not supported by you\n",
      "            then call the CompleteOrEscalate. If the user changes their mind or needs\n",
      "            help for other tasks, call the CompleteOrEscalate function to let the primary\n",
      "            host assistant take control.Do not mention who you are - just act as the\n",
      "            proxy for the assistant.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "In the quiet town of Willowbrook, Emily and James shared a love that seemed eternal. They spent their days wandering through sunlit meadows and whispering dreams under the stars. But one fateful evening, James received a letter that called him to war. Emily waited by the old oak tree every day, her heart heavy with hope. Years passed, and the letters stopped coming; James never returned, leaving Emily with only memories and a heart forever broken.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# OUTPUT\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    config = { \"configurable\": { \"thread_id\": \"1\"}}\n",
    "    events = graph.stream({\"messages\": [(\"user\", user_input)]},config,\n",
    "    stream_mode=\"values\")\n",
    "    \n",
    "    for event in events:\n",
    "        if \"messages\" in event:\n",
    "            event[\"messages\"][-1].pretty_print() \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
